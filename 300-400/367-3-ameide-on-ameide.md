# backlog/367-3 – Ameide-on-Ameide Dogfooding Program

**Parent backlog:** [backlog/367-elements-transformation-automation.md](./367-elements-transformation-automation.md)

## Purpose
Run the entire methodology + automation stack inside an Ameide tenant that manages the platform codebase itself. Demonstrates parity with customer experiences, gathers telemetry, and fuels continuous improvement.

## Scope
- Provision dedicated tenant (`ameide`) with methodology profiles (Scrum for product squads, SAFe for platform programs, TOGAF for enterprise architecture) and associated overlays/repo adapters.
- Migrate internal backlog items into the platform (feedback, PBIs, PI Objectives, ADM deliverables) with provenance.
- Enable agents (EA, solution, coding) to operate within this tenant using production guardrails; manage secrets, approvals, branching.
- Observability + reporting comparing internal vs. customer metrics (lead time, automation success rate, policy exceptions).
- Feedback loop: issues discovered via dogfooding automatically generate backlog entries tagged for remediation.
- Guardrails: prohibit side-channel merges/bypasses (all changes must flow through automation + governance) and publish an internal-vs-customer parity dashboard with agreed SLOs so gaps trigger backlog automatically.

## Deliverables
1. **Tenant bootstrap** – Scripts to seed org hierarchy, methodology profiles, repo adapters, overlays, RBAC roles, secrets.
2. **Data migration** – Import existing backlog/roadmap data, map to methodology artifacts, preserve history.
3. **Operational playbook** – How internal teams engage with the tenant (ceremonies, approvals, on-call), escalation paths, exception handling.
4. **Telemetry dashboards** – Compare automation KPIs vs. customer tenants; highlight gaps and surface parity SLO breaches.
5. **Retro loop** – Process + tools to capture dogfooding findings and convert them into backlog elements automatically.

## Non-goals
- Building methodology profiles themselves (handled earlier).
- Release governance specifics (Stage 4).

## Dependencies
- Methodology profiles + automation orchestration in place.
- Platform repos accessible via repo adapters/service accounts.
- Element graph foundations from [backlog/300-ameide-metamodel.md](./300-ameide-metamodel.md) to ensure internal telemetry mirrors customer data structures.

## Exit Criteria
- All internal platform initiatives run through the Ameide tenant using the same automation and governance features as customers.
- Metrics show coverage (percentage of work executed via automation), success/failure breakdown, and lead time improvements.
- Dogfooding findings feed a visible backlog with SLAs for resolution, and parity dashboards remain green (no unauthorized merges, exceptions tracked).

## Implementation guide

### 1. Environment & tenant bootstrap (backlog/362, backlog/329)
- Reconcile the local `ameide` cluster using [`scripts/infra/ensure-k3d-cluster.sh`](../scripts/infra/ensure-k3d-cluster.sh). Tilt auto-loads the Helmfile layers declared in [`tilt/infra_layers.tilt`](../tilt/infra_layers.tilt) and enforces baseline resources/secret stores per backlog/362.
- Seed ExternalSecret fixtures before any chart renders. [`infra/kubernetes/helmfiles/15-secrets-certificates.yaml`](../infra/kubernetes/helmfiles/15-secrets-certificates.yaml) invokes [`scripts/vault/ensure-local-secrets.py`](../scripts/vault/ensure-local-secrets.py), so onboarding must document how to run it and how to extend the fixture map when new overlays or repo adapters appear.
- Use [`scripts/infra/helm-ops.sh`](../scripts/infra/helm-ops.sh) for repeatable day‑2 ops (namespace, operators, infra, observability). This is the supported path for both local dogfooding clusters and shared stage/prod control planes.
- Automate tenant/org creation through the platform APIs: [`services/platform/src/tenants/service.ts`](../services/platform/src/tenants/service.ts) exposes Create/List/Update, while the web stack wires the bootstrap flow in [`services/www_ameide_platform/lib/auth/tenant-bootstrap.ts`](../services/www_ameide_platform/lib/auth/tenant-bootstrap.ts) and [`lib/sdk/tenants.ts`](../services/www_ameide_platform/lib/sdk/tenants.ts). The dogfood runbook must set `BOOTSTRAP_TENANT_ID=tenant-ameide` so onboarding traffic resolves to the self-hosted tenant instead of the `'system'` placeholder noted in backlog/329.
- Keep realm metadata authoritative in the tenant catalog. [`services/www_ameide_platform/lib/auth/realm-manager.ts`](../services/www_ameide_platform/lib/auth/realm-manager.ts) and [`realm-discovery.ts`](../services/www_ameide_platform/lib/auth/realm-discovery.ts) already read/write the required attributes; expand the playbook so Keycloak admin credentials, realm health probes, and emergency rotation steps are documented alongside the platform service.

### 2. Proto, SDK, CLI & guardrails (backlog/365, backlog/305)
- Treat Buf-managed protos (`../packages/ameide_core_proto`) as the single contract for automation. The repo already ships [`scripts/dev/check_sdk_alignment.py`](../scripts/dev/check_sdk_alignment.py) to fail CI when TS/Go/Python SDKs drift; keep it in the bootstrap pipeline so every dogfood tenant consumes the same generated surfaces (`packages/ameide_sdk_ts`, `packages/ameide_sdk_go`, `packages/ameide_sdk_python`).
- Client stacks must reuse the shared transports/interceptors. TypeScript services and UI call into [`packages/ameide_sdk_ts/src/client.ts`](../packages/ameide_sdk_ts/src/client.ts) which layers metadata/auth/retry/tracing interceptors from [`src/interceptors.ts`](../packages/ameide_sdk_ts/src/interceptors.ts). The Go CLI shares the same policies through [`packages/ameide_core_cli/internal/client/grpc.go`](../packages/ameide_core_cli/internal/client/grpc.go) while the portal binds transports in [`services/www_ameide_platform/hooks/useAmeideClient.ts`](../services/www_ameide_platform/hooks/useAmeideClient.ts). Dogfood scripts should wrap these helpers instead of hand‑rolling transports so tenant/request IDs are always present (per backlog/329).
- Server implementations already emit OTLP data and enforce tenant scoping. Platform and workflow services bootstrap telemetry in [`services/platform/src/telemetry.ts`](../services/platform/src/telemetry.ts) and [`services/workflows/src/grpc.ts`](../services/workflows/src/grpc.ts) using the AsyncLocal context defined in [`services/workflows/src/common/request-context.ts`](../services/workflows/src/common/request-context.ts). Make starting/stopping these observers part of the tenant bootstrap docs so the dogfood environment mirrors customer telemetry.
- Workflow orchestration is exposed through [`services/workflows/src/temporal/facade.ts`](../services/workflows/src/temporal/facade.ts) and [`services/workflows/src/status-updates.ts`](../services/workflows/src/status-updates.ts), with CLI access via [`packages/ameide_core_cli/internal/commands/workflow.go`](../packages/ameide_core_cli/internal/commands/workflow.go). Any automation that provisions repo adapters or guardrails should publish rules through these APIs to stay aligned with backlog/305.

### 3. Data migration & methodology alignment (backlog/300, backlog/303)
- Load repositories/elements via the Graph service. [`services/graph/src/graph/service.ts`](../services/graph/src/graph/service.ts) exposes create/update/list for repositories, elements, and relationships, and the portal already consumes them through [`services/www_ameide_platform/lib/sdk/elements/queries.ts`](../services/www_ameide_platform/lib/sdk/elements/queries.ts). Migration tooling should reuse these RPCs (or the Buf SDKs) so imported backlog data lands in the canonical element graph described in backlog/300/303.
- Transformations today anchor initiatives/roadmaps. The REST proxy at [`services/www_ameide_platform/app/api/transformations/route.ts`](../services/www_ameide_platform/app/api/transformations/route.ts) forwards to [`services/transformation/src/transformations/service.ts`](../services/transformation/src/transformations/service.ts), letting you seed PI objectives, sponsors, cadence metadata, etc. Extend this flow to cover the forthcoming `scrum_backlog_items`, `safe_features`, `togaf_deliverables`, `timeboxes`, and `goals` tables so Scrum/SAFe/TOGAF overlays can bind to the same backing rows without a shared neutral layer.
- Workflow definitions, versions, and automation rules persist in [`db/flyway/sql/workflows`](../db/flyway/sql/workflows) and are surfaced by [`services/workflows/src/repositories/definitions-graph.ts`](../services/workflows/src/repositories/definitions-graph.ts) plus [`repositories/rules-graph.ts`](../services/workflows/src/repositories/rules-graph.ts). Migration scripts should attach repo adapters and methodology metadata here so every auto-plan links back to the right repository (`graph_id`) or transformation (`transformation_id`).
- The Temporal worker consumes typed payloads from [`services/workflows_runtime/src/workflows_runtime/models.py`](../services/workflows_runtime/src/workflows_runtime/models.py). When importing historical runs or seeding guard rules, ensure WorkflowRunPayloads include tenant IDs, repo contexts, and methodology profile IDs so downstream parity dashboards can slice Ameide-on-Ameide vs. customer data.

### 4. Operational playbook & automation runtime (backlog/305, backlog/313)
- Document how internal squads use the portal surface. Data hooks live in [`services/www_ameide_platform/lib/api/hooks.ts`](../services/www_ameide_platform/lib/api/hooks.ts), RBAC is enforced via [`lib/auth/middleware/authorize.ts`](../services/www_ameide_platform/lib/auth/middleware/authorize.ts), and org scoping helpers sit in [`lib/auth/organization.ts`](../services/www_ameide_platform/lib/auth/organization.ts). Use these modules when scripting ceremonies (PI planning, sprint reviews) so every request carries the correct tenant/org metadata.
- Workflow operators already have UI affordances under `services/www_ameide_platform/features/workflows` (Catalog, ExecutionRuns, element panels). Reference these components when defining the dogfood runbook (how to promote a workflow, inspect runs, retry failures) to keep UI/CLI parity in sync.
- The Temporal worker entry point [`services/workflows_runtime/src/workflows_runtime/worker.py`](../services/workflows_runtime/src/workflows_runtime/worker.py) and the namespace guard [`namespace_guard.py`](../services/workflows_runtime/src/workflows_runtime/namespace_guard.py) belong in the on-call checklist—dogfood tenants must validate task queues/namespaces before accepting traffic. Guard context and status fan-out rely on [`services/workflows_runtime/src/workflows_runtime/callbacks.py`](../services/workflows_runtime/src/workflows_runtime/callbacks.py); extend this if you add tenant-specific escalation handlers.
- Align agent/runtime behaviour with the LangChain v1 plan (backlog/313). The inference service still assembles graphs via `langgraph.prebuilt.create_react_agent` (`[services/inference/agents/default.py](../services/inference/agents/default.py)` and `[services/inference/app.py](../services/inference/app.py)`), so migrating Ameide-on-Ameide to `create_agent` middleware is part of this backlog to ensure parity with what we prescribe to customers.

### 5. Telemetry & parity dashboards (backlog/362, backlog/305)
- Platform and workflow services already emit OTLP traces/metrics via [`services/platform/src/telemetry.ts`](../services/platform/src/telemetry.ts), [`services/workflows_runtime/src/workflows_runtime/telemetry.py`](../services/workflows_runtime/src/workflows_runtime/telemetry.py), and [`services/workflows/src/status-updates.ts`](../services/workflows/src/status-updates.ts). Document the environment variables (`OTEL_EXPORTER_*`, `SERVICE_VERSION`, tenant tags) required to keep those pipelines live in the dogfood tenant.
- Persist workflow run telemetry centrally. The Flyway migration [`db/flyway/sql/platform/V1__initial_schema.sql`](../db/flyway/sql/platform/V1__initial_schema.sql) seeds the `workflows_execution_status_updates` table used by WorkflowService; the implementation guide should show how to query this table (and emit Grafana dashboards) to contrast Ameide vs. customer automation success/failure rates.
- The observability stack is already packaged in [`infra/kubernetes/helmfiles/55-observability.yaml`](../infra/kubernetes/helmfiles/55-observability.yaml) (Grafana, Prometheus, Loki, Tempo, OTLP collector, Langfuse). Clarify which dashboards/prometheus queries constitute the “parity SLO” so gaps automatically open backlog items.
- Ship lightweight health tooling with the tenant. The repo includes [`scripts/telemetry/telemetry-status.sh`](../scripts/telemetry/telemetry-status.sh), [`scripts/telemetry/check-metrics.sh`](../scripts/telemetry/check-metrics.sh), [`scripts/telemetry/analyze-failures.sh`](../scripts/telemetry/analyze-failures.sh), and [`scripts/telemetry/trace-slow-ops.sh`](../scripts/telemetry/trace-slow-ops.sh); reference them in the operational playbook to keep parity checks self-serve until dedicated dashboards exist.

### 6. Guardrails, approvals & feedback loops (backlog/362, backlog/305)
- Tilt hardcodes baseline guardrails—see [`Tiltfile`](../Tiltfile) and [`tilt/infra_layers.tilt`](../tilt/infra_layers.tilt)—so even scoped `tilt up -- --only=<service>` runs still deploy secret stores, operators, and db-migrations. Emphasize this workflow for the dogfood tenant so “side-channel” deploys never bypass backlog/362 enforcement.
- Keep DB credentials and migrations deterministic. [`scripts/infra/bootstrap-db-migrations-secret.sh`](../scripts/infra/bootstrap-db-migrations-secret.sh) and [`scripts/infra/wait-for-job.sh`](../scripts/infra/wait-for-job.sh) wrap the `infra:42-db-migrations` Helm resource; the implementation guide should point SREs at these scripts instead of manual kubectl edits.
- Source control guardrails live in [`branch-protection.json`](../branch-protection.json); ensure the dogfood repos apply the same policy (required checks, linear history) so automation cannot merge directly to main.
- Runtime guardrails rely on namespace validation and tenant-aware tracing. [`services/workflows_runtime/src/workflows_runtime/namespace_guard.py`](../services/workflows_runtime/src/workflows_runtime/namespace_guard.py) prevents workers from landing in the wrong Temporal namespace, while [`services/workflows/src/temporal/facade.ts`](../services/workflows/src/temporal/facade.ts) and [`services/workflows/src/common/request-context.ts`](../services/workflows/src/common/request-context.ts) stamp tenant IDs/search attributes on every run. Use these hooks to auto-create impediment/retro entries whenever a run violates policy or bypasses automation.

## Open topics / criticalities
- **gRPC routing still targets deprecated services.** The Envoy route at `infra/kubernetes/environments/local/platform/envoy-grpc-route.yaml:16-46` only forwards `RepositoryService`, `InitiativeService`, and legacy artifact RPCs. GraphService/WorkflowService calls used by the Buf SDKs never reach the control plane, so Ameide-on-Ameide cannot exercise the current APIs until the route is updated.
- **Workflow runtime actions are placeholders.** `services/workflows_runtime/src/workflows_runtime/activities.py:183-234` simulates failures by checking for `simulate_failure` flags and never invokes repo adapters, policy bundles, or transformation APIs. Coding-agent runs therefore cannot publish evidence or diffs, blocking the automation coverage metrics called out in this backlog.
- **Scrum-specific artifact schemas are missing.** The transformation service only persists initiatives via `services/transformation/src/transformations/service.ts:61-82`; there are no tables/handlers yet for the Scrum-specific aggregates in `ameide_core_proto.transformation.scrum.v1` (Product Backlog, Product Backlog Item, Sprint, Sprint Backlog, Increment, Product Goal, Sprint Goal, Definition of Done) or their SAFe/TOGAF equivalents, so methodology overlays have nothing concrete to bind to. The data-migration plan must include these schema additions before we can ingest the internal backlog.
- **Bootstrap flows still default to a “system” tenant.** `services/www_ameide_platform/lib/auth/auto-tenant.ts:15-33` resolves tenants using `BOOTSTRAP_TENANT_ID='system'` unless operators set overrides. Without documenting/env-forcing `tenant-ameide`, the dogfood tenant will continue onboarding users into the legacy shared realm.
- **Parity dashboards focus only on auth metrics.** `scripts/telemetry/check-metrics.sh:4-44` scrapes `auth.signin.*` counters but never inspects automation coverage, workflow success/failure, or guardrail exceptions. Until we emit/monitor those metrics, the “internal vs. customer parity” SLOs described in this backlog cannot be enforced.
- **LangChain v1 adoption still blocked.** The inference runtime continues to build agents via `langgraph.prebuilt.create_react_agent` (`services/inference/agents/default.py:5-52`), so Ameide-on-Ameide will not validate the `create_agent` middleware, content_blocks, or custom middleware story from backlog/313. This needs to be upgraded before the dogfood tenant can claim LangChain parity.
