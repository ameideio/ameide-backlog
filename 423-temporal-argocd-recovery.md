# 423: Temporal ArgoCD recovery (dev)

## Context

- Temporal runs via the upstream Helm chart (`sources/charts/third_party/temporal/temporal/0.70.0`) with Postgres for default and visibility stores.
- Schema management is handled by the dedicated `data-migrations-temporal` Helm hook (runs `temporal-sql-tool`), which owns Temporal schema versions. Namespace bootstrap is a separate job (`data-temporal-namespace-bootstrap`).
- Both the migrations job and the runtime/namespace apps are generated by the `ameide-dev` `ApplicationSet` (`gitops/ameide-gitops/environments/dev/argocd/apps/ameide.yaml`), which:
  - Ensures `data-migrations-temporal` (rolloutPhase 265) runs before the Temporal runtime and namespace bootstrap apps (rolloutPhases 450/455).
  - Applies a shared `retry` policy (`limit: 10` with exponential backoff) and default `syncPolicy.automated.prune/selfHeal` for apps that don’t override it.
  - Uses RollingSync to keep Temporal dependencies ordered correctly.

See also:

- `backlog/425-vendor-schema-ownership.md` – vendor‑owned schema pattern (Temporal, CNPG).
- `backlog/420-temporal-cnpg-dev-registry-runbook.md` – broader Temporal + CNPG + dev registry story.
- `backlog/429-devcontainer-bootstrap.md` – how DevContainer bootstrap drives Argo/Temporal in dev.
- `backlog/456-ghcr-mirror.md` – GHCR mirroring for Docker Hub rate limiting; Temporal images use GHCR mirrors.

## Issues encountered

1) **Schema missing → CrashLoop**
   - Temporal frontends/matching/history/worker crashed with `schema_version` relation missing.
   - Cause: Temporal schema not applied (or partially applied), so services failed their compatibility check.

2) **Namespace bootstrap failing**
   - `data-temporal-namespace-bootstrap` Job looped with connection refused to Temporal gRPC (7233).
   - Cause: Temporal services were down due to missing schema; bootstrap couldn’t reach the endpoint.

## Fixes applied (generic recipe)

Even with `data-migrations-temporal` owning the schema and automated sync/retry enabled, you can still hit the schema-missing crash on a fresh dev cluster (e.g., if migrations ran before CNPG was fully ready, or against a previous cluster). The recovery recipe is:

- **Run Temporal migrations hook** (`data-migrations-temporal` Application) to apply Temporal schema (default + visibility) via `temporal-sql-tool`. Output should show idempotent “duplicate update” warnings if the schema is already at the desired version.
- **Restart Temporal pods** (or let Argo/Deployment restart them) so they recheck the now‑initialized schema; all Temporal deployments should converge to Running.
- **Resync namespace bootstrap** (`data-temporal-namespace-bootstrap`) once Temporal is up; the Job should complete and the app should go Healthy.
- **Argo state:** `data-temporal` and `data-temporal-namespace-bootstrap` should both be Synced/Healthy with no lingering schema errors once the above is complete.

## Verification steps (dev)

- `argocd app get argocd/data-temporal` → Health: Healthy; deployments Running.
- `argocd app get argocd/data-temporal-namespace-bootstrap` → Health: Healthy; Job succeeded.
- Temporal pods in `ameide` namespace all Running; no CrashLoopBackOff.
- Database: `schema_version` exists and reflects latest Temporal version (as reported by `temporal-sql-tool`).

## Recovery Incident: 2025-12-03

### Root Cause Analysis

The Temporal migration failed due to multiple compounding issues:

1. **PostgreSQL 15+ Schema Ownership Change**: PostgreSQL 15+ no longer grants world-writable access to the `public` schema by default. The `temporal` user could not create tables in the `public` schema of its own database because CNPG creates databases with `dbuser` as the owner.

2. **Partial Migration State**: The `temporal-sql-tool` ran `setup-schema` which created tables and set `schema_version` to `0.0`, but then `update-schema` failed on an INSERT statement (`INSERT INTO namespace_metadata`) because:
   - The job has `backoffLimit: 3`, causing retries
   - First pod created tables successfully
   - Retry pods hit "duplicate key" errors on the INSERT
   - The tool ignores "table already exists" but NOT "duplicate key" errors

3. **ArgoCD Hook State**: The migration job got stuck in "Terminating" state due to finalizers, blocking subsequent syncs.

### Fixes Applied

#### 1. CNPG Database CRD with Schema Ownership (Declarative)

Modified the postgres_clusters Helm chart to support the `schemas` field in the CNPG Database CRD:

**File**: `sources/charts/foundation/operators-config/postgres_clusters/templates/databases.yaml`
```yaml
{{- if $db.schemas }}
  schemas:
{{ toYaml $db.schemas | indent 4 }}
{{- end }}
```

**File**: `sources/values/_shared/data/platform-postgres-clusters.yaml`
```yaml
databases:
  - name: temporal
    owner: temporal
    schemas:
      - name: public
        owner: temporal
  - name: temporal-visibility
    dbName: temporal_visibility
    owner: temporal_visibility
    schemas:
      - name: public
        owner: temporal_visibility
  # ... similar for all other databases
```

This ensures each database's `public` schema is owned by the database owner, fixing the PostgreSQL 15+ permission issue.

#### 2. Migration Job Idempotency (Added but Incomplete)

Added version checking to the migration job to skip if schema is already at target version:

**File**: `sources/charts/platform-layers/temporal-migrations/templates/job.yaml`
- Added `version_gte()` function to compare version strings
- Calls `temporal-sql-tool describe-schema` before running migrations
- Skips migration if current version >= target version

**File**: `sources/values/_shared/data/data-migrations-temporal.yaml`
```yaml
databases:
  default:
    targetVersion: "1.18"
  visibility:
    targetVersion: "1.9"
```

**Note**: This idempotency check helps for future runs but doesn't handle partial migration states where tables exist but version is 0.0.

#### 3. Manual Recovery of Partial State

When migration failed mid-way (tables created, version=0.0, namespace_metadata row inserted):

```bash
# Delete the conflicting row that caused duplicate key errors
kubectl exec -n ameide data-temporal-admintools-... -- \
  env PGPASSWORD=dbpassword psql \
  -h platform-postgres-clusters-rw.ameide.svc.cluster.local \
  -U temporal -d temporal \
  -c "DELETE FROM namespace_metadata WHERE partition_id = 54321;"

# Delete stuck job and clear ArgoCD operation state
kubectl delete job data-migrations-temporal-temporal-migrations -n ameide --force --grace-period=0
kubectl patch application data-migrations-temporal -n argocd --type=merge -p '{"operation": null}'

# Trigger fresh sync
kubectl annotate application data-migrations-temporal -n argocd argocd.argoproj.io/refresh=hard --overwrite
kubectl patch application data-migrations-temporal -n argocd --type=merge -p '{"operation": {"initiatedBy": {"username": "admin"}, "sync": {"prune": true}}}'
```

### Final State

After recovery:
- `temporal` database: schema version **1.18**
- `temporal_visibility` database: schema version **1.9**
- All Temporal pods: **Running**
- ArgoCD apps: `data-migrations-temporal`, `data-temporal`, `data-temporal-namespace-bootstrap` all **Synced/Healthy**

### Automation Follow-up: Guaranteed Re-runs + Setup Guardrail (2025-12-04)

To avoid manual intervention the next time the hook needs to run:

1. **Hook auto-trigger** – The `data-migrations-temporal` Helm chart now derives the `force-trigger` annotation automatically from the chart version + target schema versions. Any bump to either value causes ArgoCD to see a diff and rerun the pre-install hook; no more timestamp edits in `sources/values/_shared/data/data-migrations-temporal.yaml`.
2. **Skip duplicate `setup-schema`** – The hook template now calls `setup-schema` only if `describe-schema` fails. If the schema already exists (even if the version is stuck at `0.0`), the job jumps straight to `update-schema`, which prevents the duplicate-key crash that previously required manual clean-up.

> **Reminder:** The namespace bootstrap job (`data-temporal-namespace-bootstrap`) still depends on Temporal’s gRPC endpoint. Run the migrations first, ensure the Temporal deployments are healthy, and only then re-sync the namespace bootstrap Application.

### Files Modified

| File | Change |
|------|--------|
| `sources/charts/foundation/operators-config/postgres_clusters/templates/databases.yaml` | Added `schemas` field support |
| `sources/charts/foundation/operators-config/postgres_clusters/values.yaml` | Added schemas to all database definitions |
| `sources/values/_shared/data/platform-postgres-clusters.yaml` | Added schemas with correct owners for all databases |
| `sources/charts/platform-layers/temporal-migrations/templates/job.yaml` | Added version checking for idempotency |
| `sources/charts/platform-layers/temporal-migrations/values.yaml` | Added `targetVersion` to database configs |
| `sources/values/_shared/data/data-migrations-temporal.yaml` | Added `targetVersion` for default (1.18) and visibility (1.9) |

### Known Limitations

1. **temporal-sql-tool limitations**: The tool's `update-schema` command doesn't treat "duplicate key" INSERT errors as ignorable (unlike "table already exists"). This can cause failures on retry if the first attempt partially succeeded.

2. **Partial state recovery**: If a migration fails mid-way, manual intervention may be needed to either:
   - Delete conflicting rows and re-run
   - Drop the database entirely and re-run (destructive)

3. **Hook triggering**: ArgoCD hooks only run when there are actual resource changes. Adding a `force-trigger` annotation to the job values can help trigger re-runs when needed.

## Guardrails / follow-ups

- Keep Temporal schema ownership in the dedicated Temporal migrations job; rerun `data-migrations-temporal` before Temporal upgrades to ensure compatibility (see `backlog/425-vendor-schema-ownership.md`).
- If Temporal pods crash with schema errors, rerun `data-migrations-temporal`, then restart pods or allow Argo to resync, then rerun namespace bootstrap as needed.
- Monitor first rollout after Temporal version bumps for schema compatibility checks; document any vendor‑specific caveats in this backlog and cross‑link from `backlog/420-temporal-cnpg-dev-registry-runbook.md` and `backlog/429-devcontainer-bootstrap.md`.
- **PostgreSQL 15+ compatibility**: Always ensure CNPG Database CRDs include `schemas` with correct ownership for the database owner.
- **Partial migration recovery**: If migration job fails with "duplicate key" errors, check the database state and delete conflicting rows before re-running.

## Recovery Incident: 2025-12-05

### Root Cause Analysis

This incident combined password mismatch with the existing partial migration state issues:

1. **Password Mismatch Between CNPG and Temporal Services**: The CNPG credential consolidation created TWO separate entries that generated DIFFERENT passwords:
   - `temporal-db-env` (used by Temporal services) - one random password
   - `temporal-db-credentials` (used by CNPG role) - different random password

   Result: Temporal services couldn't authenticate to Postgres because CNPG set the role password from `temporal-db-credentials`, but services connected using `temporal-db-env`.

2. **Migration Job Missing Tolerations**: The `temporal-migrations` Helm chart didn't support `nodeSelector`/`tolerations`, causing pods to remain Pending on dev nodes with `ameide.io/environment: dev` taint.

3. **Partial Migration State** (same as 2025-12-03): Multiple job retries caused duplicate key errors on `INSERT INTO namespace_metadata`.

### Fixes Applied

#### 1. Consolidated Temporal Credentials (commit `8d4a519`)

Removed duplicate credential entries and updated CNPG to use the same secret as Temporal services:

**File**: `sources/values/_shared/data/platform-postgres-clusters.yaml`
```yaml
# Before: CNPG and Temporal used different secrets
managed:
  roles:
    - name: temporal
      passwordSecret:
        name: temporal-db-credentials  # Different password!

# After: CNPG uses same secret as Temporal
managed:
  roles:
    - name: temporal
      passwordSecret:
        name: temporal-db-env  # Same password as Temporal services
    - name: temporal_visibility
      passwordSecret:
        name: temporal-visibility-db-env
```

Also removed duplicate entries `temporal-password` and `temporal-visibility-password` from `credentials.appUsers`.

#### 2. Updated Temporal Helm Values (commit `6adcdb6`)

Changed secret references in Temporal chart to use the consolidated `-db-env` secrets:

**File**: `sources/values/_shared/data/data-temporal.yaml`
```yaml
server:
  config:
    persistence:
      default:
        sql:
          existingSecret: temporal-db-env  # was: temporal-db-credentials
      visibility:
        sql:
          existingSecret: temporal-visibility-db-env  # was: temporal-visibility-db-credentials
```

#### 3. Added Tolerations to Migration Job (commit `2e9acb0`)

**File**: `sources/charts/platform-layers/temporal-migrations/templates/job.yaml`
```yaml
spec:
  template:
    spec:
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
```

This allows the migration job to schedule on environment-specific nodes using tolerations from `globals.yaml`.

### Recovery Steps (for partial state)

When migration failed mid-way with databases in partial state:

```bash
# 1. Drop and recreate databases cleanly
kubectl exec -n ameide-dev postgres-ameide-1 -- psql -U postgres -c "DROP DATABASE IF EXISTS temporal;"
kubectl exec -n ameide-dev postgres-ameide-1 -- psql -U postgres -c "DROP DATABASE IF EXISTS temporal_visibility;"

# 2. Delete CNPG Database CRDs to trigger recreation
kubectl delete database postgres-ameide-temporal postgres-ameide-temporal-visibility -n ameide-dev

# 3. Sync postgres-clusters to recreate databases
kubectl annotate application dev-platform-postgres-clusters -n argocd argocd.argoproj.io/refresh=hard --overwrite
kubectl patch application dev-platform-postgres-clusters -n argocd --type=merge \
  -p '{"operation": {"initiatedBy": {"username": "admin"}, "sync": {"prune": true}}}'

# 4. Wait for databases to be created, then trigger migration
kubectl delete application dev-data-migrations-temporal -n argocd --wait=false
# ApplicationSet will recreate it and trigger hooks

# 5. After migration completes, refresh Temporal app
kubectl annotate application dev-data-temporal -n argocd argocd.argoproj.io/refresh=hard --overwrite
kubectl rollout restart deployment -n ameide-dev -l app.kubernetes.io/name=temporal
```

### Environment Isolation

The credential consolidation preserves per-environment password isolation:

1. **Helm lookup is namespace-scoped**: `lookup "v1" "Secret" $namespace $secretName` only finds secrets in the target namespace
2. **Each environment gets unique passwords**: Dev/staging/prod have separate secrets generated in their respective ArgoCD syncs
3. **No cross-env secret sharing**: The consolidation only affects secrets **within** each environment

### Files Modified

| File | Change |
|------|--------|
| `sources/values/_shared/data/platform-postgres-clusters.yaml` | Removed duplicate temporal-password entries; updated CNPG managed.roles to use `-db-env` secrets |
| `sources/values/_shared/data/data-temporal.yaml` | Updated existingSecret references to use `-db-env` secrets |
| `sources/charts/platform-layers/temporal-migrations/templates/job.yaml` | Added nodeSelector and tolerations support |
| `sources/charts/platform-layers/temporal-namespace-bootstrap/templates/namespace-bootstrap-job.yaml` | Added nodeSelector and tolerations support (commit `7270a0b`) |

### Verification

```bash
# Passwords match within environment (CNPG role and Temporal service use same)
kubectl get secret temporal-db-env -n ameide-dev -o jsonpath='{.data.password}' | base64 -d

# Schema versions after successful migration
kubectl exec -n ameide-dev postgres-ameide-1 -- psql -U postgres -d temporal -c "SELECT curr_version FROM schema_version;"
# Should show: 1.18

kubectl exec -n ameide-dev postgres-ameide-1 -- psql -U postgres -d temporal_visibility -c "SELECT curr_version FROM schema_version;"
# Should show: 1.9

# Temporal pods healthy
kubectl get pods -n ameide-dev -l app.kubernetes.io/name=temporal
```

### Final State

Recovery completed successfully:
- `temporal` database: schema version **1.18**
- `temporal_visibility` database: schema version **1.9**
- All 10 Temporal pods: **Running**
- ArgoCD apps: `dev-data-migrations-temporal`, `dev-data-temporal`, `dev-data-temporal-namespace-bootstrap` all **Synced/Healthy**

## Recovery Incident: 2025-12-05 (GHCR Mirror Alignment)

### Root Cause Analysis

This incident occurred during GHCR mirror alignment (backlog/456-ghcr-mirror.md):

1. **Busybox init container missing `nc` command**: The Temporal init container was using `cgr.dev/chainguard/busybox` which doesn't include the `nc` (netcat) command needed for the wait-for-backends script.

2. **Migration job using Docker Hub image**: The `temporal-migrations` job was using `temporalio/admin-tools` from Docker Hub, which was rate-limited.

3. **Partial migration state**: Previous failed migration attempts left the databases in partial state with `schema_version` at 0.0 and duplicate key conflicts in `namespace_metadata`.

4. **Old pods stuck in Init:0/1**: Old ReplicaSets had pods stuck waiting on the old busybox image.

### Fixes Applied

#### 1. GHCR Busybox Mirror (commit in session)

Changed Temporal init container to use GHCR mirror with netcat support:

**File**: `sources/values/_shared/data/data-temporal.yaml`
```yaml
additionalInitContainers:
  - name: wait-for-backends
    # Using GHCR mirror to avoid Docker Hub rate limits
    image: ghcr.io/ameideio/mirror/busybox:1.36.1
```

#### 2. GHCR Migration Job Image (commit in session)

**File**: `sources/values/_shared/data/data-migrations-temporal.yaml`
```yaml
image:
  repository: ghcr.io/ameideio/mirror/temporalio-admin-tools
  tag: "1.29.1-tctl-1.18.4-cli-1.5.0"
imagePullSecrets:
  - ghcr-pull
```

### Recovery Steps

```bash
# 1. Delete conflicting namespace_metadata row
kubectl exec -n ameide-dev data-temporal-admintools-... -- \
  env PGPASSWORD=... psql -h platform-postgres-clusters-rw.ameide-dev.svc.cluster.local \
  -U temporal -d temporal -c "DELETE FROM namespace_metadata WHERE partition_id = 54321;"

# 2. Delete old stuck pods (Init:0/1 from old ReplicaSets)
kubectl delete pod -n ameide-dev <old-init-stuck-pods> --force --grace-period=0

# 3. Restart affected Temporal deployments
kubectl rollout restart deployment -n ameide-dev \
  data-temporal-frontend data-temporal-matching data-temporal-worker

# 4. Delete failed namespace-bootstrap job and re-sync
kubectl delete job data-temporal-namespace-bootstrap-temporal-namespace-bootstrap \
  -n ameide-dev --force --grace-period=0
kubectl annotate application dev-data-temporal-namespace-bootstrap -n argocd \
  argocd.argoproj.io/refresh=hard --overwrite
kubectl patch application dev-data-temporal-namespace-bootstrap -n argocd \
  --type merge -p '{"operation":{"initiatedBy":{"username":"admin"},"sync":{"prune":true}}}'
```

### Final State

Recovery completed successfully:
- `temporal` database: schema version **1.18**
- `temporal_visibility` database: schema version **1.9**
- All 10 Temporal pods: **Running**
- ArgoCD apps: `dev-data-migrations-temporal`, `dev-data-temporal`, `dev-data-temporal-namespace-bootstrap` all **Synced/Healthy**

### Files Modified

| File | Change |
|------|--------|
| `sources/values/_shared/data/data-temporal.yaml` | Changed busybox to GHCR mirror |
| `sources/values/_shared/data/data-migrations-temporal.yaml` | Added GHCR mirror for admin-tools image |
