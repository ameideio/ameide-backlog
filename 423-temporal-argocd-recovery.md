# 423: Temporal ArgoCD recovery (dev)

## Context

- Temporal runs via the upstream Helm chart (`sources/charts/third_party/temporal/temporal/0.70.0`) with Postgres for default and visibility stores.
- Schema management is handled by the dedicated `data-migrations-temporal` Helm hook (runs `temporal-sql-tool`), which owns Temporal schema versions. Namespace bootstrap is a separate job (`data-temporal-namespace-bootstrap`).
- Both the migrations job and the runtime/namespace apps are generated by the `ameide-dev` `ApplicationSet` (`gitops/ameide-gitops/environments/dev/argocd/apps/ameide.yaml`), which:
  - Ensures `data-migrations-temporal` (rolloutPhase 265) runs before the Temporal runtime and namespace bootstrap apps (rolloutPhases 450/455).
  - Applies a shared `retry` policy (`limit: 10` with exponential backoff) and default `syncPolicy.automated.prune/selfHeal` for apps that don’t override it.
  - Uses RollingSync to keep Temporal dependencies ordered correctly.

See also:

- `backlog/425-vendor-schema-ownership.md` – vendor‑owned schema pattern (Temporal, CNPG).
- `backlog/420-temporal-cnpg-dev-registry-runbook.md` – broader Temporal + CNPG + dev registry story.
- `backlog/429-devcontainer-bootstrap.md` – how DevContainer bootstrap drives Argo/Temporal in dev.

## Issues encountered

1) **Schema missing → CrashLoop**
   - Temporal frontends/matching/history/worker crashed with `schema_version` relation missing.
   - Cause: Temporal schema not applied (or partially applied), so services failed their compatibility check.

2) **Namespace bootstrap failing**
   - `data-temporal-namespace-bootstrap` Job looped with connection refused to Temporal gRPC (7233).
   - Cause: Temporal services were down due to missing schema; bootstrap couldn’t reach the endpoint.

## Fixes applied (generic recipe)

Even with `data-migrations-temporal` owning the schema and automated sync/retry enabled, you can still hit the schema-missing crash on a fresh dev cluster (e.g., if migrations ran before CNPG was fully ready, or against a previous cluster). The recovery recipe is:

- **Run Temporal migrations hook** (`data-migrations-temporal` Application) to apply Temporal schema (default + visibility) via `temporal-sql-tool`. Output should show idempotent “duplicate update” warnings if the schema is already at the desired version.
- **Restart Temporal pods** (or let Argo/Deployment restart them) so they recheck the now‑initialized schema; all Temporal deployments should converge to Running.
- **Resync namespace bootstrap** (`data-temporal-namespace-bootstrap`) once Temporal is up; the Job should complete and the app should go Healthy.
- **Argo state:** `data-temporal` and `data-temporal-namespace-bootstrap` should both be Synced/Healthy with no lingering schema errors once the above is complete.

## Verification steps (dev)

- `argocd app get argocd/data-temporal` → Health: Healthy; deployments Running.
- `argocd app get argocd/data-temporal-namespace-bootstrap` → Health: Healthy; Job succeeded.
- Temporal pods in `ameide` namespace all Running; no CrashLoopBackOff.
- Database: `schema_version` exists and reflects latest Temporal version (as reported by `temporal-sql-tool`).

## Guardrails / follow-ups

- Keep Temporal schema ownership in the dedicated Temporal migrations job; rerun `data-migrations-temporal` before Temporal upgrades to ensure compatibility (see `backlog/425-vendor-schema-ownership.md`).
- If Temporal pods crash with schema errors, rerun `data-migrations-temporal`, then restart pods or allow Argo to resync, then rerun namespace bootstrap as needed.
- Monitor first rollout after Temporal version bumps for schema compatibility checks; document any vendor‑specific caveats in this backlog and cross‑link from `backlog/420-temporal-cnpg-dev-registry-runbook.md` and `backlog/429-devcontainer-bootstrap.md`.
